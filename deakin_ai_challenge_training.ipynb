{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "deakin_ai_challenge_training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Fj2O3Au9xdS"
      },
      "source": [
        "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "#  Copyright (c) 2020. Reda Bouadjenek, Deakin University                      +\n",
        "#     Email:  reda.bouadjenek@deakin.edu.au                                    +\n",
        "#                                                                              +\n",
        "#  Licensed under the Apache License, Version 2.0 (the \"License\");             +\n",
        "#   you may not use this file except in compliance with the License.           +\n",
        "#    You may obtain a copy of the License at:                                  +\n",
        "#                                                                              +\n",
        "#                 http://www.apache.org/licenses/LICENSE-2.0                   +\n",
        "#                                                                              +\n",
        "#    Unless required by applicable law or agreed to in writing, software       +\n",
        "#    distributed under the License is distributed on an \"AS IS\" BASIS,         +\n",
        "#    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  +\n",
        "#    See the License for the specific language governing permissions and       +\n",
        "#    limitations under the License.                                            +\n",
        "#                                                                              +\n",
        "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fusNkGWA9qF4"
      },
      "source": [
        "# Run this to install the appropriate packages\n",
        "!pip uninstall tensorboard -y\n",
        "!pip uninstall tensorflow-estimator -y\n",
        "!pip uninstall tensorflow-gpu -y\n",
        "!pip install tensorflow==2.2.0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbbWh-959k8g"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, balanced_accuracy_score, accuracy_score\n",
        "from tensorflow.keras import models, layers, optimizers\n",
        "from tensorflow.python.keras.saving import hdf5_format\n",
        "from keras.preprocessing.image import ImageDataGenerator, DirectoryIterator\n",
        "import h5py, itertools, collections\n",
        "import itertools\n",
        "\n",
        "\n",
        "##################\n",
        "# Verifications:\n",
        "#################\n",
        "print(\"GPU is user?: \" + str(tf.test.is_gpu_available()))\n",
        "print(\"Tensorflow version: \" + tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r62rx-yX97GE"
      },
      "source": [
        "# Download dataset.\n",
        "!wget http://206.12.93.90:8080/simpson_dataset/simpsons_train.tar.gz\n",
        "!tar -xzvf simpsons_train.tar.gz > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpgROocq9k8k"
      },
      "source": [
        "'''\n",
        "    Split train and validation.\n",
        "'''\n",
        "image_size = (128, 128)\n",
        "batch_size = 64\n",
        "\n",
        "image_generator = ImageDataGenerator(validation_split=0.1)\n",
        "\n",
        "train_ds =  DirectoryIterator(\n",
        "    \"dataset/simpsons_train/\",\n",
        "    image_generator,\n",
        "    class_mode='categorical',\n",
        "    seed=1337,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    subset = 'training',\n",
        ")\n",
        "val_ds = DirectoryIterator(\n",
        "    \"dataset/simpsons_train/\",\n",
        "    image_generator,\n",
        "    class_mode='categorical',\n",
        "    seed=1337,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    subset = 'validation',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "class_names = list(train_ds.class_indices.keys())\n",
        "num_classes = train_ds.num_classes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "HjIlDsQW9k8m"
      },
      "source": [
        "###############################################\n",
        "#### Show distribution of images per class.\n",
        "###############################################\n",
        "\n",
        "counter=collections.Counter(train_ds.labels)\n",
        "v = [ [class_names[item[0]],item[1]]  for item in counter.items()]\n",
        "df = pd.DataFrame(data=v, columns=['index','value'])\n",
        "g = sns.catplot(x='index', y= 'value',  data=df, kind='bar', \n",
        "                legend=False,height=4,aspect=4,saturation=1)\n",
        "(g.despine(top=False,right=False))\n",
        "plt.xlabel(\"Classes\")\n",
        "plt.ylabel(\"#images\")\n",
        "plt.title(\"Distribution of images per class\")\n",
        "# params = {'legend.fontsize': '16',\n",
        "#           'axes.labelsize': 18,\n",
        "#           'axes.titlesize': 14,\n",
        "#           'xtick.labelsize': 18,\n",
        "#           'ytick.labelsize': 18,\n",
        "#           'axes.titlepad': 25}\n",
        "# plt.rcParams.update(params)\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#####################################\n",
        "######### Show sample of images.\n",
        "#####################################\n",
        "\n",
        "\n",
        "plt.figure(figsize=(16, 16))\n",
        "images = []\n",
        "labels = []\n",
        "for itr in train_ds.next():\n",
        "    for i in range(25):\n",
        "        if len(images) < 25:\n",
        "            images.append(itr[i].astype(\"uint8\"))\n",
        "        else:\n",
        "            labels.append(list(itr[i]).index(1))\n",
        "\n",
        "for i in range(len(images)):\n",
        "    ax = plt.subplot(5, 5, i + 1)\n",
        "    plt.imshow(images[i])\n",
        "    plt.title(class_names[labels[i]]+' ('+str(int(labels[i]))+')')\n",
        "    plt.axis(\"off\")\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dhx9ZVzlV9CE"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(keras.Input(shape=image_size + (3,))) \n",
        "model.add(layers.experimental.preprocessing.Rescaling(1./255))\n",
        "# CNN block 1\n",
        "model.add(layers.Conv2D(32, kernel_size=3, activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "# # CNN block 2     \n",
        "model.add(layers.Conv2D(64, kernel_size=3, activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "# # CNN block 3       \n",
        "model.add(layers.Conv2D(128, kernel_size=3, activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "#Dense part\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
        "              loss='CategoricalCrossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "VtOTspgk9k8r"
      },
      "source": [
        "history = model.fit(\n",
        "    train_ds, epochs=5, \n",
        "    validation_data=val_ds,\n",
        ")\n",
        "with h5py.File('model_sample_epochs_128_128_5.h5', mode='w') as f:\n",
        "    hdf5_format.save_model_to_hdf5(model, f)\n",
        "    f.attrs['class_names'] = class_names\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ObvEJffXxiC",
        "scrolled": false
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "# balanced_acc = history.history['my_balanced_accuracy_score']\n",
        "# val_balanced_acc = history.history['val_my_balanced_accuracy_score']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "\n",
        "# ax1 = plt.subplot(1, 2, 1)\n",
        "\n",
        "plt.plot(epochs, loss, label='Training loss')\n",
        "plt.plot(epochs, val_loss, label='Validation loss')\n",
        "plt.fill_between(epochs, loss,val_loss,color='g',alpha=.1)\n",
        "\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# ax2 = plt.subplot(1, 2, 2)\n",
        "\n",
        "plt.plot(epochs, acc, label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, label='Validation accuracy')\n",
        "plt.fill_between(epochs, acc,val_acc,color='g',alpha=.1)\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozFeX6Xu9k8w"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    vmax = cm.max()\n",
        "    if normalize:\n",
        "        title = 'Confusion matrix (normalized)'\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        cm = [[int(j*100) for j in i ] for i in cm]\n",
        "        cm =np.array(cm)\n",
        "        vmax = 100\n",
        "        \n",
        "    plt.figure(figsize=(8,8))\n",
        "\n",
        "    im = plt.imshow(cm, interpolation='nearest', cmap=cmap, vmin=0.0, vmax=vmax)\n",
        "    plt.title(title)\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=90)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    \n",
        "    \n",
        " \n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "#     plt.tight_layout() \n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.colorbar(im,fraction=0.046, pad=0.04)\n",
        "#     m.set_clim(0., 2.)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc5KeKBT9k8y"
      },
      "source": [
        "y_prob = model.predict(val_ds)\n",
        "y_predict = y_prob.argmax(axis=-1)\n",
        "y_true = val_ds.labels\n",
        "cnf_matrix = confusion_matrix(y_true, y_predict)\n",
        "plot_confusion_matrix(cm=cnf_matrix, classes=class_names, title='Confusion Matrix',normalize=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLtmeRirH_ZA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}